{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Path' from 'os' (/Users/deniz/opt/anaconda3/envs/comp411/lib/python3.7/os.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-95a9581699da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Path' from 'os' (/Users/deniz/opt/anaconda3/envs/comp411/lib/python3.7/os.py)"
     ]
    }
   ],
   "source": [
    "# Faster RCNN network to find and classify cells in images with Pytorch\n",
    "\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.utils as utils\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import math\n",
    "import cv2\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the csv file as a pandas dataframe\n",
    "df_train = pd.read_csv(\"QC/df_train.csv\")\n",
    "df_valid = pd.read_csv(\"QC/df_valid.csv\")\n",
    "df_test = pd.read_csv(\"QC/df_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class where the inputs are:\n",
    "# df: a dataframe that contains the image id, classification and xmax, xmin, ymin, ymax for the bounding box\n",
    "# image_dir and transforms\n",
    "class CellDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transforms=None):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.image_ids = self.df[\"image_id\"].unique()\n",
    "        self.image_dir = os.path(image_dir)\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.image_ids.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        records = self.df[self.df[\"image_id\"] == image_id]\n",
    "\n",
    "        # get the image\n",
    "        image_name = image_id + \".png\"\n",
    "        image = Image.open(os.path.join(self.image_dir, image_name)).convert(\"RGB\")\n",
    "        image = transforms.ToTensor()(image)\n",
    "\n",
    "        # get the bounding box coordinates\n",
    "        boxes = records[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.int64)\n",
    "\n",
    "\n",
    "        # get the classification\n",
    "        labels = torch.tensor(records[\"super_classification\"].values, dtype=torch.int64)\n",
    "        \n",
    "\n",
    "        # create a target dictionary\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = torch.tensor([idx])\n",
    "\n",
    "\n",
    "        # apply the transformations\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "            \n",
    "        return image, target, image_id\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Faster RCNN model\n",
    "model = models.detection.fasterrcnn_resnet50_fpn_v2(pretrained=True, progress=True, num_classes=5, pretrained_backbone=True, \n",
    "                                trainable_backbone_layers=0, image_mean=[0.485, 0.456, 0.406], image_std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# Train the model for 5 epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Define the optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# Define the loss function\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the device\n",
    "model.to(device)\n",
    "\n",
    "# Define the training and validation datasets\n",
    "train_dataset = CellDataset(df_train, \"QC/images/\", transforms=transforms.Compose([transforms.ToTensor()]))\n",
    "valid_dataset = CellDataset(df_valid, \"QC/images/\", transforms=transforms.Compose([transforms.ToTensor()]))\n",
    "test_dataset = CellDataset(df_test, \"QC/images/\", transforms=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# Define the training and validation dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4, collate_fn=utils.collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=True, num_workers=4, collate_fn=utils.collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True, num_workers=4, collate_fn=utils.collate_fn)\n",
    "\n",
    "# Define the training loop\n",
    "def train_model(model, loss_func, optimizer, lr_scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch, num_epochs - 1))\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"valid\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over the data\n",
    "            for images, targets, image_ids in dataloaders[phase]:\n",
    "                \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp411",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
