{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster RCNN network to find and classify cells in images with Pytorch\n",
    "\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.utils as utils\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import math\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the csv file as a pandas dataframe\n",
    "df_train = pd.read_csv(\"QC/df_train.csv\")\n",
    "df_valid = pd.read_csv(\"QC/df_valid.csv\")\n",
    "df_test = pd.read_csv(\"QC/df_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class where the inputs are:\n",
    "# df: a dataframe that contains the image id, classification and xmax, xmin, ymin, ymax for the bounding box\n",
    "# image_dir and transforms\n",
    "class CellDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transforms=None):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.image_ids = self.df[\"image_id\"].unique()\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.image_ids.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        records = self.df[self.df[\"image_id\"] == image_id]\n",
    "\n",
    "        # get the image\n",
    "        image_name = image_id + \".png\"\n",
    "        image = Image.open(os.path.join(self.image_dir, image_name)).convert(\"RGB\")\n",
    "        image = transforms.ToTensor()(image)\n",
    "\n",
    "        # get the bounding box coordinates\n",
    "        boxes = records[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.int64)\n",
    "\n",
    "\n",
    "        # get the classification\n",
    "        labels = torch.tensor(records[\"super_classification\"].values, dtype=torch.int64)\n",
    "        \n",
    "\n",
    "        # create a target dictionary\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = torch.tensor([idx])\n",
    "\n",
    "\n",
    "        # apply the transformations\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "            \n",
    "        return image, target, image_id\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deniz/opt/anaconda3/envs/comp411/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/Users/deniz/opt/anaconda3/envs/comp411/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_V2_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/Users/deniz/opt/anaconda3/envs/comp411/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained_backbone' is deprecated since 0.13 and may be removed in the future, please use 'weights_backbone' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/Users/deniz/opt/anaconda3/envs/comp411/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights_backbone' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights_backbone=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights_backbone=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Define the Faster RCNN model\n",
    "model = models.detection.fasterrcnn_resnet50_fpn_v2(pretrained=True, progress=True, pretrained_backbone=True, \n",
    "                                trainable_backbone_layers=0, image_mean=[0.485, 0.456, 0.406], image_std=[0.229, 0.224, 0.225])\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes=5)\n",
    "\n",
    "# Train the model for 5 epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Define the optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# Define the loss function\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the device\n",
    "model.to(device)\n",
    "\n",
    "# Define the training and validation datasets\n",
    "train_dataset = CellDataset(df_train, \"QC/rgb/\", transforms=transforms.Compose([transforms.ToTensor()]))\n",
    "valid_dataset = CellDataset(df_valid, \"QC/rgb/\", transforms=transforms.Compose([transforms.ToTensor()]))\n",
    "test_dataset = CellDataset(df_test, \"QC/rgb/\", transforms=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# Define the training and validation dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "# Define the training loop\n",
    "def train_model(model, loss_func, optimizer, lr_scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch, num_epochs - 1))\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"valid\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "            print(\"Phase: {}\".format(phase))\n",
    "            # Iterate over the data\n",
    "            loader = train_loader if phase == \"train\" else valid_loader\n",
    "            for images, targets, image_ids in tqdm(loader):\n",
    "                print(\"58\")\n",
    "                images = list(image.to(device) for image in images)\n",
    "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "                print(\"61\")\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(images, targets)\n",
    "                    print(\"69\")\n",
    "                    loss = sum(loss for loss in outputs.values())\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        print(\"75\")\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            if phase == \"train\":\n",
    "                lr_scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / len(loader.dataset)\n",
    "\n",
    "            print(\"{} Loss: {:.4f}\".format(phase, epoch_loss))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == \"valid\" and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(\"Training complete in {:.0f}m {:.0f}s\".format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print(\"Best val loss: {:4f}\".format(best_loss))\n",
    "\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/436 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "train_model(model, loss_func, optimizer, lr_scheduler, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp411",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
