{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Path' from 'os' (/Users/deniz/opt/anaconda3/envs/comp411/lib/python3.7/os.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-95a9581699da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Path' from 'os' (/Users/deniz/opt/anaconda3/envs/comp411/lib/python3.7/os.py)"
     ]
    }
   ],
   "source": [
    "# Faster RCNN network to find and classify cells in images with Pytorch\n",
    "\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.utils as utils\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import math\n",
    "import cv2\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>super_classification</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-AR-A0U4-DX1_id-5ea40a88ddda5f8398990ccf_l...</td>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "      <td>83</td>\n",
       "      <td>176</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-AC-A6IW-DX1_id-5ea40997ddda5f83989810a2_l...</td>\n",
       "      <td>2</td>\n",
       "      <td>149</td>\n",
       "      <td>258</td>\n",
       "      <td>164</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-A2-A0YE-DX1_id-5ea40a24ddda5f839898afb8_l...</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>276</td>\n",
       "      <td>93</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-GM-A2DH-DX1_id-5ea40adcddda5f83989951a2_l...</td>\n",
       "      <td>4</td>\n",
       "      <td>204</td>\n",
       "      <td>88</td>\n",
       "      <td>233</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-E2-A1LH-DX1_id-5ea40a58ddda5f839898e0ed_l...</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>203</td>\n",
       "      <td>76</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id  super_classification  \\\n",
       "0  TCGA-AR-A0U4-DX1_id-5ea40a88ddda5f8398990ccf_l...                     4   \n",
       "1  TCGA-AC-A6IW-DX1_id-5ea40997ddda5f83989810a2_l...                     2   \n",
       "2  TCGA-A2-A0YE-DX1_id-5ea40a24ddda5f839898afb8_l...                     3   \n",
       "3  TCGA-GM-A2DH-DX1_id-5ea40adcddda5f83989951a2_l...                     4   \n",
       "4  TCGA-E2-A1LH-DX1_id-5ea40a58ddda5f839898e0ed_l...                     1   \n",
       "\n",
       "   xmin  ymin  xmax  ymax  \n",
       "0   135    83   176   123  \n",
       "1   149   258   164   275  \n",
       "2    63   276    93   293  \n",
       "3   204    88   233   103  \n",
       "4    35   203    76   243  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the csv file as a pandas dataframe\n",
    "df = pd.read_csv(\"QC/df_train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class where the inputs are:\n",
    "# df: a dataframe that contains the image id, classification and xmax, xmin, ymin, ymax for the bounding box\n",
    "# image_dir and transforms\n",
    "class CellDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transforms=None):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.image_ids = self.df[\"image_id\"].unique()\n",
    "        self.image_dir = os.path(image_dir)\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.image_ids.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        records = self.df[self.df[\"image_id\"] == image_id]\n",
    "\n",
    "        # get the image\n",
    "        image_name = image_id + \".png\"\n",
    "        image = Image.open(os.path.join(self.image_dir, image_name)).convert(\"RGB\")\n",
    "        image = transforms.ToTensor()(image)\n",
    "\n",
    "        # get the bounding box coordinates\n",
    "        boxes = records[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.int64)\n",
    "\n",
    "\n",
    "        # get the classification\n",
    "        labels = torch.tensor(records[\"super_classification\"].values, dtype=torch.int64)\n",
    "        \n",
    "\n",
    "        # create a target dictionary\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = torch.tensor([idx])\n",
    "\n",
    "\n",
    "        # apply the transformations\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "            \n",
    "        return image, target, image_id\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp411",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
